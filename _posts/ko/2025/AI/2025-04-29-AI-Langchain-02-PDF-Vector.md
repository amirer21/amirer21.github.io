---
title: ì¸ê³µì§€ëŠ¥ - Langchainì„ í™œìš©í•œ ì§ˆë¬¸ ì‘ë‹µ ì‹œìŠ¤í…œ êµ¬ì¶• (ë²¡í„° DBì™€ GPT ëª¨ë¸ ê²°í•©)
author_profile: true
read_time: true
comments: true
share: true
related: true
categories:
- AI
- LangChain
- LLM
- ChatGPT
tags:
- AI
- LangChain
- LLM
- ChatGPT
toc: true
toc_sticky: true
toc_label: ëª©ì°¨
description: ì¸ê³µì§€ëŠ¥ - Langchainì„ í™œìš©í•œ ì§ˆë¬¸ ì‘ë‹µ ì‹œìŠ¤í…œ êµ¬ì¶• (ë²¡í„° DBì™€ GPT ëª¨ë¸ ê²°í•©)
article_tag1: AI
article_tag2: GPT
article_tag3: LLM
article_section: 
meta_keywords: AI, GPT, LLM, LangChain
last_modified_at: '2025-04-28 21:00:00 +0800'
---


## Langchainì„ í™œìš©í•œ ì§ˆë¬¸ ì‘ë‹µ ì‹œìŠ¤í…œ êµ¬ì¶• (ë²¡í„° DBì™€ GPT ëª¨ë¸ ê²°í•©)

## ğŸ§  LangChainìœ¼ë¡œ ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ ì‘ë‹µ ì‹œìŠ¤í…œ ë§Œë“¤ê¸°  
### PDF ë¬¸ì„œë¥¼ ê²€ìƒ‰ ê°€ëŠ¥í•œ LLM ì§€ì‹ìœ¼ë¡œ ë°”ê¾¸ëŠ” ì²« ê±¸ìŒ

LLM(GPT ê°™ì€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸)ì€ ì•„ì£¼ ë˜‘ë˜‘í•˜ì§€ë§Œ, **"ê¸°ì–µë ¥"ì€ ì§§ìŠµë‹ˆë‹¤**.  
ì¦‰, ëª¨ë¸ì´ ë¯¸ë¦¬ í•™ìŠµí•œ ë°ì´í„° ì™¸ì— **ìµœì‹  ë¬¸ì„œ**ë‚˜ **íŠ¹ì • ê¸°ê´€ì˜ ë‚´ë¶€ ìë£Œ**ì— ëŒ€í•œ ì§ˆë¬¸ì—ëŠ” ë‹µí•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.

ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ë ¤ë©´?  
â†’ **ë¬¸ì„œë¥¼ ì§ì ‘ ê²€ìƒ‰í•´ì„œ ëª¨ë¸ì—ê²Œ ì „ë‹¬í•˜ëŠ” êµ¬ì¡°**, ì¦‰ **RAG(Retrieval-Augmented Generation)**ê°€ í•„ìš”í•©ë‹ˆë‹¤.

ì´ë²ˆ ê¸€ì—ì„œëŠ” LangChainì„ ì´ìš©í•´ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤:

```
PDF ë¬¸ì„œ â†’ í…ìŠ¤íŠ¸ ë¶„í•  â†’ ë²¡í„°í™” â†’ ë²¡í„° DB ì €ì¥ â†’ ê²€ìƒ‰ â†’ GPT ì‘ë‹µ ìƒì„±
```

---

## ğŸ› ï¸ ì‹¤ìŠµ ëª©í‘œ

- âœ… PDF ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì™€ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³ 
- âœ… ì ì ˆí•œ ë‹¨ìœ„ë¡œ ìª¼ê°œê³ 
- âœ… ì„ë² ë”©ì„ í†µí•´ ë²¡í„°í™”í•˜ê³ 
- âœ… FAISS ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•œ í›„
- âœ… ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì•„ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ 
- âœ… GPTë¡œë¶€í„° ìµœì¢… ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

---

## 1. ğŸ”§ ê¸°ë³¸ í™˜ê²½ ì„¤ì •

```python
import os
import warnings
from dotenv import load_dotenv
from openai import OpenAI

warnings.filterwarnings("ignore", category=UserWarning)
load_dotenv(dotenv_path='openapi_key.env')  # API í‚¤ ë¡œë“œ
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)
```

`.env` íŒŒì¼ì— ì €ì¥ëœ OpenAI í‚¤ë¥¼ ë¶ˆëŸ¬ì™€ **GPT ëª¨ë¸ì„ ì‚¬ìš©í•  ì¤€ë¹„**ë¥¼ í•©ë‹ˆë‹¤.

---

## 2. ğŸ“„ ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸° ë° í…ìŠ¤íŠ¸ ë¶„í• 

```python
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from glob import glob

def create_vector_db():
    alldoc = []
    for path in glob('./test_source/*.pdf'):
        loader = PyPDFLoader(path)
        documents = loader.load()
        splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=20)
        chunks = splitter.split_documents(documents)
        alldoc.extend(chunks)

    return alldoc
```

- **PyPDFLoader**: PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ  
- **Text Splitter**: í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ì‘ì€ ë‹¨ìœ„ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤ (í† í° ì´ˆê³¼ ë°©ì§€)

---

## 3. ğŸ”¢ ë²¡í„°í™” ë° FAISS ì¸ë±ì‹±

```python
from langchain_openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS

docs = create_vector_db()
embedding_model = OpenAIEmbeddings()
vector_db = FAISS.from_documents(docs, embedding_model)
```

- ê° í…ìŠ¤íŠ¸ ì¡°ê°ì€ **OpenAI ì„ë² ë”© ëª¨ë¸**ë¡œ ë³€í™˜ë˜ì–´ ë²¡í„°ë¡œ ë°”ë€ë‹ˆë‹¤.
- ì´ ë²¡í„°ë“¤ì„ FAISS DBì— ì €ì¥í•˜ë©´ **ì§ˆë¬¸ì— ê°€ì¥ ê°€ê¹Œìš´ ë¬¸ì„œë¥¼ ë¹ ë¥´ê²Œ ê²€ìƒ‰**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## 4. ğŸ¤– ì§ˆë¬¸ â†’ ê²€ìƒ‰ â†’ ì‘ë‹µ ìƒì„±

```python
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI

gpt = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)
retriever = vector_db.as_retriever()
qa_chain = RetrievalQA.from_chain_type(llm=gpt, chain_type='stuff', retriever=retriever)
```

- **RetrievalQA**: ê²€ìƒ‰ + ìƒì„± ìë™ ì¡°í•© ì²´ì¸
- `chain_type='stuff'`: ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ê·¸ëŒ€ë¡œ GPTì— **ë¶™ì—¬ì„œ ì „ë‹¬**í•˜ëŠ” ê°€ì¥ ë‹¨ìˆœí•œ ë°©ì‹

---

## 5. ğŸ“¥ ì§ˆë¬¸í•˜ê³  ë‹µ ë°›ì•„ë³´ê¸°

```python
query = '2021ë…„ ì„œìš¸ì‹œ ì°½ì—…ì§€ì› ì‚¬ì—…ì— ëŒ€í•œ ì˜ˆì‚°ì€ ì–¼ë§ˆì¸ê°€?'
result = qa_chain.invoke({'query': query})
print("ë‹µë³€:", result['result'])
```

GPTê°€ **ë²¡í„° ê²€ìƒ‰ì„ í†µí•´ ì°¾ì•„ë‚¸ ë¬¸ì„œ ë‚´ìš©**ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê²Œ ì‘ë‹µí•©ë‹ˆë‹¤.

---

## ğŸ“Œ ì´ ì‹¤ìŠµìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆëŠ” ê²ƒë“¤

| ì´í•´ í•­ëª© | ì„¤ëª… |
|-----------|------|
| âœ… ë¬¸ì„œ ê²€ìƒ‰ ê¸°ë°˜ ì‘ë‹µ ìƒì„± | ë‹¨ìˆœ GPT ì‚¬ìš©ì„ ë„˜ì–´, **ì™¸ë¶€ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µì„ ë§Œë“œëŠ” êµ¬ì¡°** í•™ìŠµ |
| âœ… ë²¡í„° DBì˜ í•„ìš”ì„± | ë¬¸ì„œê°€ ë§ì„ ë•Œë„ ë¹ ë¥´ê³  ì •í™•í•œ ê²€ìƒ‰ì„ ìœ„í•œ **FAISS ë²¡í„° ê²€ìƒ‰** |
| âœ… LangChain êµ¬ì„± íë¦„ | ë¬¸ì„œ ë¡œë”© â†’ ë¶„í•  â†’ ì„ë² ë”© â†’ ê²€ìƒ‰ â†’ ì‘ë‹µê¹Œì§€ì˜ ì²´ì¸ êµ¬ì¶• ì´í•´ |

---

## âœ… ë§ˆë¬´ë¦¬

ì´ ê¸€ì—ì„œ ìš°ë¦¬ëŠ” LangChain, FAISS, OpenAIë¥¼ í™œìš©í•´  
**PDF ë¬¸ì„œë¥¼ ê²€ìƒ‰ ê°€ëŠ¥í•œ LLM ì§€ì‹ ê¸°ë°˜**ìœ¼ë¡œ ë°”ê¾¸ëŠ” êµ¬ì¡°ë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

ì´ ì‹œìŠ¤í…œì€ ë‹¤ìŒ ë‹¨ê³„ë¡œ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- ëŒ€í™”í˜• ì‘ë‹µ (`ConversationalRetrievalChain`)
- ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹(JSON, CSV ë“±) ì§€ì›
- ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ reranker ë„ì…

---

ë‹¤ìŒ ê¸€ì—ì„œëŠ” ì´ ì‹œìŠ¤í…œì„ **ëŒ€í™”í˜•ìœ¼ë¡œ í™•ì¥**í•˜ëŠ” ë°©ë²•, ì¦‰  
â€œ**ê¸ˆì•¡ë§Œ ì•Œë ¤ì¤˜**â€ ê°™ì€ **ë¬¸ë§¥ì„ ê¸°ì–µí•˜ëŠ” ì‘ë‹µ** ì‹œìŠ¤í…œìœ¼ë¡œ ë°œì „ì‹œì¼œë³´ê² ìŠµë‹ˆë‹¤! ğŸš€
