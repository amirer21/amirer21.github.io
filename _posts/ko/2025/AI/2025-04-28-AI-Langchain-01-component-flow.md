---
title: (LangChain) LangChain 구성요소 완벽 이해하기 - 한눈에 보는 흐름
author_profile: true
read_time: true
comments: true
share: true
related: true
categories:
- AI
- LangChain
- LLM
- ChatGPT
tags:
- AI
- LangChain
- LLM
- ChatGPT
toc: true
toc_sticky: true
toc_label: 목차
description: 인공지능 - LangChain 구성요소 완벽 이해하기 - 한눈에 보는 흐름
article_tag1: AI
article_tag2: GPT
article_tag3: LLM
article_section: 
meta_keywords: AI, GPT, LLM, LangChain
last_modified_at: '2025-04-28 21:00:00 +0800'
---


# 🧩 LangChain 구성요소 완벽 이해하기 - 한눈에 보는 흐름

생성형 AI(Generative AI)를 활용해 **"문서에서 답변하기"** 시스템을 만들고 싶다면,  
반드시 거쳐야 하는 필수 구조가 있습니다.

오늘은 **LangChain의 핵심 구성요소와 흐름**을 한눈에 정리해보겠습니다.  
아래 이미지는 이 과정을 매우 깔끔하게 보여주고 있습니다.

> ✨ 한 줄 요약: **입력 → 문서 로드 → 텍스트 분할 → 벡터 저장 → 검색 → 답변 생성**  

이제 단계별로 자세히 살펴보겠습니다.

---

## 📄 LangChain 구성요소 흐름

### 1. 입력 (Prompt Template)

- 사용자가 작성한 **프롬프트 템플릿**이 시작점입니다.
- 예를 들어,  
  `"문서를 요약해줘"`  
  `"이 문서에서 톰 소여에 대한 정보를 알려줘"`  
  같은 요청을 준비합니다.

---

### 2. 도큐먼트 로더 (Document Loader)

- 문서, 이메일, 데이터베이스 등에서 **원본 문서**를 불러옵니다.
- 예시:
  - PDF 파일 열기
  - 웹사이트 URL 읽기
  - DB에서 텍스트 가져오기
- 가져온 내용은 **"도큐먼트(Document)"** 형태로 변환됩니다.

---

### 3. 스플리터 (Splitter)

- 하나의 긴 문서를 **짧은 조각(Split)** 으로 나눕니다.
- 예시:
  - 500자 단위로 텍스트 분할
  - 챕터별로 나누기
- 이 과정을 통해 LLM이 다룰 수 있는 크기로 맞춥니다.  
(※ LLM은 입력 토큰 수에 제한이 있기 때문입니다.)

---

### 4. 저장 (Vector Store)

- 분할된 조각을 **임베딩(Embedding)** 해서 **벡터 DB**에 저장합니다.
- 여기서 중요한 포인트:
  - 텍스트를 의미(semantics) 기반으로 숫자 벡터로 변환
  - FAISS, Pinecone 같은 벡터 저장소에 등록
- 즉, **"문자열"이 아니라 "의미"를 저장**하는 단계입니다.

---

### 5. 검색 (Retrieval)

- 사용자가 질문(Query)을 입력하면,
- 질문도 임베딩(벡터화)해서
- **벡터 DB**에서 의미적으로 가장 비슷한 조각들을 찾아냅니다.
- 예시:
  > "등장인물" 질문 → "톰 소여 등장 부분" 문서 조각 검색

**Retrieval**은 가장 중요한 단계 중 하나입니다.  
**"검색된 문맥(Context)"이 답변 품질을 결정**합니다.

---

### 6. 출력 (Prompt + LLM)

- 검색된 문서 조각을 **프롬프트**와 함께 LLM에게 전달합니다.
- LLM이 질문에 맞게 최종 **답변(Answer)** 을 생성합니다.

결과적으로,  
> **문서에서 관련 내용만 추출해 질문에 맞는 정확한 답변을 생성**하는 구조가 완성됩니다.

---

## 📈 전체 흐름 다시 요약하면

| 단계 | 설명 |
|:---|:---|
| 입력 | 사용자의 질문이나 요청 템플릿 준비 |
| 문서 로드 | PDF, 웹페이지 등에서 문서 불러오기 |
| 텍스트 분할 | 문서를 적당한 크기로 나누기 |
| 벡터 저장 | 의미 기반 임베딩 생성 후 저장 |
| 검색 | 질문과 가장 유사한 문서 조각 찾기 |
| 답변 생성 | 검색된 문맥을 기반으로 LLM이 답변 |

---

## 🎯 이 구조를 왜 알아야 할까?

| 이유 | 설명 |
|:---|:---|
| 맞춤형 AI 서비스 개발 | 내 문서, 내 데이터에 대해 답변하는 시스템을 만들 수 있습니다. |
| RAG 시스템의 기본 | Retrieval + Generation 방식의 핵심입니다. |
| LLM의 한계 극복 | 기억하지 못하는 부분을 문서 검색으로 보완할 수 있습니다. |
| 생산성 향상 | 검색 → 답변 생성 과정을 자동화할 수 있습니다. |

---

# ✨ 마무리

**LangChain의 구성요소**를 이해하는 것은  
그냥 모델을 호출하는 단계를 넘어서  
> **"나만의 데이터로 작동하는 AI 시스템"을 만드는 첫걸음**입니다.

지금부터라도 이 흐름을 머릿속에 자연스럽게 그릴 수 있도록 연습해보세요! 🚀

---

# 🚀 다음 글 예고

다음에는  
👉 "**LangChain 문서 로더 종류 및 사용법**"  
👉 "**Splitter 전략(Chunk 크기, Overlap) 최적화 방법**"  
도 함께 소개하겠습니다!
