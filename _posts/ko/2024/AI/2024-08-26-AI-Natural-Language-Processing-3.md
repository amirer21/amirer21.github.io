---
title: 인공지능 - 자연어 처리 과정
author_profile: true
read_time: true
comments: true
share: true
related: true
categories:
- AI
- NLP
tags:
- AI
- NLP
toc: true
toc_sticky: true
toc_label: 목차
description: 인공지능 - 자연어 처리 과정
article_tag1: AI
article_tag2: NLP
article_tag3: 
article_section: 
meta_keywords: AI, NLP
last_modified_at: '2024-08-26 21:00:00 +0800'
---


# 🧩 자연어 처리(NLP) 과정 — 텍스트를 이해하는 AI의 여정

**자연어 처리(NLP)**는 단순히 문장을 읽는 것에서 끝나지 않습니다.  
컴퓨터가 인간 언어를 "진짜 이해"하려면 여러 단계를 거쳐야 하죠.

> ✨ "NLP 과정"이란,  
> **텍스트를 입력받아 의미를 파악하고 원하는 결과를 내기까지 거치는 일련의 단계**를 말합니다.

오늘은 자연어 처리의 전형적인 흐름을 단계별로 살펴보겠습니다.

---

## 📄 자연어 처리 전체 흐름 요약

| 단계 | 설명 |
|:---|:---|
| 1. 텍스트 수집 | 분석할 문서, 대화, 기사 등 데이터를 모음 |
| 2. 전처리(Preprocessing) | 텍스트를 정리하고 깨끗하게 만듦 |
| 3. 토크나이징(Tokenizing) | 문장을 단어/문장 등의 단위로 나눔 |
| 4. 임베딩(Embedding) | 텍스트를 벡터(숫자 배열)로 변환 |
| 5. 모델 학습/추론 | 의미를 이해하거나, 분류/요약/답변 생성 |
| 6. 결과 후처리(Postprocessing) | 사람이 보기 좋은 형태로 결과 정리 |

---

## 🛠 자연어 처리 주요 단계 자세히 보기

### 1. 텍스트 수집

- 뉴스, 블로그, SNS, 책, 대화 기록 등에서 필요한 텍스트 데이터를 모읍니다.
- 데이터 품질이 매우 중요합니다.

예시:
> 다양한 주제의 뉴스 기사 수집

---

### 2. 전처리 (Preprocessing)

- **불필요한 기호**, **HTML 태그**, **오타** 등을 제거합니다.
- **소문자 변환**, **숫자 통일**, **특수문자 삭제** 등.

예시:
> "Hello!!! How are you???" → "hello how are you"

✅ **왜 필요한가?**  
텍스트를 정리하면 모델이 더 정확하게 학습할 수 있습니다.

---

### 3. 토크나이징 (Tokenizing)

- 문장을 **단어**, **문장**, **서브워드** 같은 작은 단위로 나눕니다.

예시:
> "나는 학교에 간다" → ["나는", "학교에", "간다"]

또는
> "unbelievable" → ["un", "believe", "able"]

✅ **왜 필요한가?**  
컴퓨터는 "문장 전체"를 바로 이해하지 못합니다.  
작게 쪼개야 의미 단위를 분석할 수 있습니다.

---

### 4. 임베딩 (Embedding)

- 토큰(단어)을 **숫자 벡터**로 변환합니다.
- 예를 들어, "school"이라는 단어를 768차원 벡터로 표현합니다.

✅ **왜 필요한가?**  
컴퓨터는 "단어"가 아니라 "숫자"만 처리할 수 있기 때문입니다.

> [0.12, -0.34, 0.88, ..., -0.01] 처럼.

✅ **임베딩은 무엇을 나타내나?**  
비슷한 뜻을 가진 단어는 비슷한 벡터를 가집니다.

예시:
- "school"과 "university"는 벡터 공간에서 가깝다.
- "apple"과 "banana"는 가깝지만, "apple"과 "car"는 멀다.

---

### 5. 모델 학습 및 추론

- 벡터화된 데이터를 이용해 모델이 학습하거나,
- 또는 이미 학습된 모델(GPT, BERT 등)을 사용해 결과를 생성합니다.

여기서 다양한 작업을 수행합니다:
- **문서 분류** (정치, 스포츠, 경제)
- **감성 분석** (긍정/부정)
- **요약 생성** (긴 기사 요약)
- **질문 답변** (문서 기반으로 답변)

---

### 6. 결과 후처리 (Postprocessing)

- 모델의 출력을 사람이 읽기 쉽게 다듬습니다.
- 예를 들면, 요약문의 문장 부호 정리, 불필요한 텍스트 제거 등.

✅ **최종 목표**  
> 사용자가 자연스럽게 이해할 수 있는 결과 제공

---

## 📈 그림으로 보는 NLP 과정

```
[텍스트 수집] → [전처리] → [토크나이징] → [임베딩] → [모델 학습/추론] → [결과 후처리]
```

---

## 🎯 자연어 처리 과정의 핵심 포인트

| 항목 | 설명 |
|:---|:---|
| Garbage In, Garbage Out | 데이터가 엉망이면 모델 결과도 엉망 |
| 전처리와 토크나이징 | 텍스트 품질을 결정하는 핵심 작업 |
| 임베딩 벡터화 | 의미를 수치화하는 핵심 기술 |
| 튼튼한 모델 | 대규모 데이터와 좋은 아키텍처 필요 |
| 후처리 | 결과를 사람이 보기 좋게 다듬는 마무리 |

---

# 📝 마무리

정리하면,

> 자연어 처리는 텍스트를 **정리하고 쪼개고 숫자로 바꾼 뒤**,  
> **모델로 의미를 분석하거나 문장을 생성하는 기술**입니다.

단순히 모델을 부르는 것처럼 보이지만,  
그 뒤에는 **정교한 전처리 → 임베딩 → 의미 파악** 과정이 숨어 있습니다.

---

# 🚀 다음 글 예고

👉 "**임베딩(Embedding)이란? 왜 중요한가?**"  
👉 "**토크나이징 전략 비교 (WordPiece vs SentencePiece 등)**"  
👉 "**Transformer가 자연어 처리를 어떻게 혁신했나?**"
